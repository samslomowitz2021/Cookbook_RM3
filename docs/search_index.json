[["index.html", "Multivariate Statistics for Data Science Preface", " Multivariate Statistics for Data Science Samuel Slomowitz 2022-01-04 Preface This is in my RM3 Cookbook. It contains all the methods I worked in in RM3. "],["pca.html", "Chapter 1 Inference Prinicipal Component Analysis 1.1 Description of Method and Data 1.2 Heatmap: Correlation matrix 1.3 Analysis 1.4 Summary", " Chapter 1 Inference Prinicipal Component Analysis 1.1 Description of Method and Data 1.1.1 Method In data analysis, PCA reduces the dimensions in a multivariate data set. It maximizes variance on uncorrelated variables, which are created at the time of data analysis (Jolliffe and Cadima, 2016). The first principal component extracts the maximum explained variance or inertia from the data table.The second component must be orthogonal to the first, and have the second largest variance. The rest of the components take on the next biggest level of variance until the final component retains the smallest level of variance. Factor scores are the new values corresponding to the observations and can be projected on to the principal components graphically. 1.1.2 Data The data set is a survey of over 927 participants, after omitting missing observations with missing values, on 19 variables related to music. Survey questions are rated on an scale 0-5 with 0 being low and 5 being high. For example, a 5 on Music Interest is high preference for an interest in music while a 1 on Tempo preference indicates a liking of slow tempo. The age of the participants is 15 to 30. The survey assessed music preferences. head(df5) %&gt;% kbl() %&gt;% kable_paper(&quot;hover&quot;, full_width = F) Music Fast Dance Folk Country Classical Musical Pop Rock Metal Punk Hiphop Reggae Swing RnR Alt Lat Techno Opera 5 3 2 1 2 2 1 5 5 1 1 1 1 1 3 1 1 1 1 4 4 2 1 1 1 2 3 5 4 4 1 3 1 4 4 2 1 1 5 5 2 2 3 4 5 3 5 3 4 1 4 3 5 5 5 1 3 5 3 2 1 1 1 1 2 2 1 4 2 2 1 2 5 1 2 1 5 3 4 3 2 4 3 5 3 1 2 5 3 2 1 2 4 2 2 5 3 2 3 2 3 3 2 5 5 3 4 3 4 4 5 3 1 3 1.2 Heatmap: Correlation matrix The correlation plot show that Punk and Dance, Rock and Roll and Rock, Opera and Classical, and Techno and Dance are fairly correlation to each while Metal, Punk and Rock form a strong cluster of correlation values. There is an argument to be made that a covariance matrix is best for survey data, that is a matrix that is not normalized so that questions with a large variance take up more importance than questions with a small variance. In other words, to equalize the questions by scaling would take away the effect of question father from the center of gravity. corrplot(cor(mt25), # Correlation matrix method = &quot;shade&quot;, # Correlation plot method type = &quot;full&quot;, # Correlation plot style (also &quot;upper&quot; and &quot;lower&quot;) diag = TRUE, # If TRUE (default), adds the diagonal tl.col = &quot;black&quot;, # Labels color bg = &quot;white&quot;, # Background color title = &quot;&quot;, # Main title col = NULL) 1.3 Analysis The variable inf.pca contains descriptive and inference data. The eigenvalues, for example, are the amount of variance in the corresponding principal components. I decided to run a seed set to generate a consistent set of random sample to make my functions reproducible. set.seed(91) A PCA with inference was run using epPCA.inference.battery() using scaled and centered data. Permutation testing and bootstraping were run as well. res_pcaInf &lt;- epPCA.inference.battery(df5, center = TRUE, scale = &quot;SS1&quot;, DESIGN = df4$Gender, graphs = FALSE, test.iters = 999) 1.3.1 Testing the eigenvalues I decided to remove the code for the histograms of the eigenvalues as it showed a p-value of much less than 0.05. Thus, the eigenvalues were shown to be significant. It is a good practice to personally run a permutation test on eigenvalues for inference PCA, as this includes inferential statistical methods like bootstrap that may not have intrinsic value without a visualization technique like a histogram of the eigenvalues. 1.3.2 Scree Plot with Permutation Testing The scree plot is a visualization of the eigenvalues that contain the most explained variance along with statistical significance indicated by the color violet and non-statistical significant indicated by the color black. The significance level is based on a permutation test, which is a resampling without replacement. Thus, the null hypothesis can be evaluated to be true or false. Since three dimensions are significant, I will be creating two sets of factor score plots. The Scree plot is independent of the DESIGN variable. The Scree Plot revealed that at least three eigenvalues are important for the component analysis. The elbow-rule states that when the screen plot goes from a step decline to a flat horizontal, the dimension on the steep-decline, or the first three dimensions in our case, are of importance. It is important to center in PCA since the mean contains the largest amount of explained variance. Thus, if the data is not centered, the first dimension would capture the variance that the mean contributed to the data set. my.scree &lt;- PlotScree(ev = res_pcaInf$Fixed.Data$ExPosition.Data$eigs, p.ev = res_pcaInf$Inference.Data$components$p.vals) 1.3.3 Row Factor Scores new_color = res_pcaInf$Fixed.Data$Plotting.Data$fi.col new_color = recode(new_color, &quot;#84BF30&quot; = &quot;blue&quot;, &quot;#305ABF&quot; = &quot;deeppink&quot;) my.fi.plot &lt;- createFactorMap(res_pcaInf$Fixed.Data$ExPosition.Data$fi, display.labels = FALSE, # data title = &quot;Music Row Factor Scores&quot;, # title of the plot axis1 = 1, axis2 = 2, # which component for x and y axes pch = 19, # the shape of the dots (google `pch`) cex = 2, # the size of the dots text.cex = 2.5, # the size of the text alpha.points = 0.1, col.points = new_color, # color of the dots col.labels = res_pcaInf$Fixed.Data$Plotting.Data$fi.col, # color for labels of dots ) The observation factor scores are projected on the first two dimension with the DESIGN variable of gender, blue for males and pink for females. It seems at first glance to be uniformly dispersed, but subsequent analytic tools will confirm that or reveal subtle gender distinctions. As the Scree plot indicated, the Row Factor Score plot shows 20% of the variance on the x-axis or first dimension and 14% of the variance on the y-axis or second dimension. fi.plot &lt;- my.fi.plot$zeMap + fi.labels # you need this line to be able to save them in the end fi.plot 1.3.4 Row Factor Scores with Means Here the means of the row factor scores under the DESIGN of gender show a clear separation along the second dimension and a subtle distinction along the first dimension. As we project the variables later on, we will be able to link gender with certain music preferences. Thus, we can make sense of the large data table with nineteen dimensions and thousands of data points. 1.3.5 Row Factor Scores with Tolerance interval The Tolerance Interval contains a p-value of .95 indicating geometrically where 95% of the population lies in the factor score map. While there is much overlap, female group spreads towards the third quadrant while the male group spread toward the first quadrant. This will further quantify how we can interpret future graphs with specific variables going to spefific groups of observations. TIplot &lt;- MakeToleranceIntervals(res_pcaInf$Fixed.Data$ExPosition.Data$fi, design = as.factor(df4$Gender), col = grp.col[row.names(fi.mean)], line.size = .50, line.type = 3, alpha.ellipse = .2, alpha.line = .4, p.level = .95) # If you get some errors with this function, check the names.of.factors argument in the help. fi.WithMeanTI &lt;- my.fi.plot$zeMap_background + my.fi.plot$zeMap_dots + fi.mean.plot$zeMap_dots + fi.mean.plot$zeMap_text + TIplot + fi.labels fi.WithMeanTI 1.3.6 Bootstrap interval We can also add the bootstrap interval for the group means to see if these group means are significantly different. The BootCube has bootstapped means 1,000 times for each group by 19 variables.It is generated by the user before making a confidence interval ellipse for PCA. The first step is to bootstrap the group means, with 1,000 iterations. Thus, we are resampling with replacement one thousand times, and we can calculate means and confidence intervals on those resampled sets of data. Bootstrap interval is a subset of a confidence interval, which is a statistical descriptor that validates if the population mean or statistic falls within say 95% of the samples. In a bootstap inerval, the samples are the resampling data sets with replacement. # Depend on the size of your data, this might take a while fi.boot &lt;- Boot4Mean(res_pcaInf$Fixed.Data$ExPosition.Data$fi, design = df4$Gender, niter = 1000) # Check what you have #fi.boot # What is the cube? Check the first 4 tables. You don&#39;t need to include this in # your output, because it&#39;s a lot of junk text. #fi.boot$BootCube[,,1:4] On the plot of the bootstrap interval, the bootstrap intervals closely surrounds the groups means, and they are non-overlapping. Where as the tolerance interval geogrpahically outlines 95% of the observations, the bootstrap interval outlines 95% of the means from the resampling. Thus 95% of the group means of males are distinct from 95% of the group means of females. # Check other parameters you can change for this function bootCI4mean &lt;- MakeCIEllipses(fi.boot$BootCube[,c(1:2),], # get the first two components col = grp.col[row.names(fi.mean)]) fi.WithMeanCI &lt;- my.fi.plot$zeMap_background + bootCI4mean + my.fi.plot$zeMap_dots + fi.mean.plot$zeMap_dots + fi.mean.plot$zeMap_text + fi.labels fi.WithMeanCI 1.3.7 Loadings Loadings can be defined several ways such as the sum of squares of 1 single component summing to 1, the sum of squares of a single variables summing to 1, or the sum of squares of all of the variables summing to q or the total inertia, which is the total variance. Metal, Punk, Rock, and Alternative are separated from the other variables along the second dimension while Techno, Hiphop, Pop, and Dance are separated fromthe other variables alond the first dimension. Since mean of males was above the x-axis, males tend to like metal, punk, rock, and alternative. Females tend to like everything else, especially Latino, Musical, Folk, Swing, Classical, and Rock and Roll. These later groups go in the positive direction toward females and the negative direction can be projected back towards males. Thus, males do not like Latino, Musical, Folk, Swing, Classical, and Rock and Roll. Additionally, the first dimension seems to separate Techo, Hiphop, Pop, and Dance, which tend to be fast tempo songs from the rest of the genres which range from moderate to slow. The variance of each component is plotted for the factor scores for the variables. We see that the biggest amount of variance comes from those away from the center of gravity. Thus, Metal, Punk, Rock, Alternative, Rock and Roll, Opera, Swing, Musical, Latino, Pop, Dance, and Hiphop capture the largest amounts of variance compared to the other variables. 1.3.8 Dimensions 2 and 3 Below are the Components 2 and 3 plotted based on the results of the Scree Plot. The pink dot (females) are more dispersed away from the center of gravity and in third and fourth quadrant. The blue dot (males) overlap in the center of gravity and above the x-axis. The third dimension retains 11% of the total variance of the data set. The males and females seem to form distinct groups. Further, it is surprising that the female is still close to the origin. However, upon closer examination there are several female observations on the periphery, especially in the second and third quadrant. Here, the gender DESIGN is split along the second dimension. The third dimension shows little group distinction along the DESIGN of gender. The tolerance interval seems to show a convex hull with the protrusion of 95% of female observations extending into the second, third, and fouth quadrants. The Confidence intervals are non-overlapping, indicating a clear separation between groups. 1.3.9 Loadings / Circle of Correlation Like before, the second dimension shows that males like Rock, Punk, Metal, and Alternative while females like everything else. The third dimension shows that males like the same genres of Rock, Punk, Metal, and Alternative while females like Latino, Musical, Opera, and Classical. This is consistent to what was seen in the first dimension. Component 2: Rock Concert Music vs. everything else Interpret: Males align with the Rock Concert Music genres. Component 3: Orchestra, Folk, and Ethic (Latino) music vs. everything else. Interpret: Females align with the Orchestra, Folk, and Ethic (Latino) music genres. 1.3.10 Contribution barplots and Bootstrap Ratios on Variables Here we are resampling the factor scores for the variables with replacement to generate benchmarks for how stable the data variables are in the analysis, specifically testing the stability of the original results. If a set of variables in the analysis are key to the conclusions, one can see if they are shown to also be important in the bootstrap ratios. signed.ctrJ &lt;- res_pcaInf$Fixed.Data$ExPosition.Data$cj * sign(res_pcaInf$Fixed.Data$ExPosition.Data$fj) # plot contributions for component 1 ctrJ.1 &lt;- PrettyBarPlot2(signed.ctrJ[,1], threshold = 1 / NROW(signed.ctrJ), font.size = 3, signifOnly = TRUE, color4bar = gplots::col2hex(df5.col), # we need hex code ylab = &#39;Contributions&#39;, ylim = c(1.2*min(signed.ctrJ[,1]), 1.2*max(signed.ctrJ[,1])), horizontal = FALSE ) + ggtitle(&quot;Contribution barplots&quot;, subtitle = &#39;Component 1: Variable Contributions (Signed)&#39;) The the next line of code puts the figures side to side. As stated before, males were explained to like Rock, Punk, Metal, and Alternative as shown by the second dimension. Punk and Metal are shown to contribute to the second dimension importantly while Rock and Alternative do not. However, all four genres of Rock, Punk, Metal, and Alternative have significant bootstrap ratios. Taken both results together, Punk and Metal can be strongly argued for both contributing to the second dimension enough and being stable enough to link them to the male gender over female gender in terms of preference. grid.arrange( as.grob(ctrJ.1), as.grob(ctrJ.2), as.grob(ba001.BR1), as.grob(ba002.BR2), ncol = 2,nrow = 2, top = textGrob(&quot;Barplots for variables&quot;, gp = gpar(fontsize = 18, font = 3)) ) The second takeaway from above is that female survey participants showed a preference for Latino, Musical, Opera, and Classical as explained by the first and third dimensions. Opera and Classical contribute to the both the first and third dimensions while all four genres have significant bootstrap ratios for the first dimension and Musical, Opera, and Classical hve significant bootstrap ratios for the third dimension. Taken together, we can say that Opera and Classical contribute importantly to the first and third dimension and have significant bootstrap ratios for those dimension. Thus, we can strongly argue that females have a preference for Opera and Classical over male survey participants. ### Save figures to PPT The following code can give you a .pptx file with all the figures saved in the directory. REMEMBER: Never use a screen shot # Here we can save all figures to a PowerPoint #savedList &lt;- saveGraph2pptx(file2Save.pptx = &#39;AllFigures_inf5&#39;, #title = &#39;All Figures for inference5&#39;, #addGraphNames = TRUE) 1.4 Summary Component 1 Rows: Survey Participants Cols: Fast Songs VS Slower to moderately tempo songs Interpret: Aside from Gender, fast/dance music differs from vs. slower to moderately tempo songs Component 2 Rows: Survey Participants Cols: Rock Concert Music Interpret: Rock Concert Music differs from traditional and popular party music Males tend to prefer Rock, Punk, Metal, and Alternative as told by the second dimension while females tend to like Latino, Musical, Opera, and Classical as told by the first and third dimensions. Bibliography 1. https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0202 "],["ca.html", "Chapter 2 Correspondence Analysis 2.1 The data pattern 2.2 Analysis 2.3 Summary", " Chapter 2 Correspondence Analysis Correspondence Analysis is similar to PCA, but is meant for qualitative data. Factor scores are generated for rows and columns, and both sets of factor scores have the same variance. Thus, they can be plotted on the same map for the analysis. CA also has distributional equivalence. Thus, merging two rows with the same profile does not affect the output and the output would be identical. A profile is a relative proportion versus an absolute number as in PCA. While PCA minimizes the sum of square of distance, CA minimized the sum of squares of mass times distance squared or Inertia. The data set contains 120 consumers who evaluated their emotions upon tasting 5 types of low income sausages. The objective was to then related these reported emotions to their sensory profiles. The participants were all female from either Mexico City or Monterrey. The data table is a contingency table. Thus, variables are on the rows and columns while observations are the items of the table. Further, in a contingency table, the observations are independence from one other. The research question of this section is: Do types of low-income sausages differ in the emotional responses people attribute to them? The observations for Happy emotions for the Alpino sausages is 27. Each observation has one sausage type and one emotion survey response. head(mt1) %&gt;% kbl() %&gt;% kable_paper(&quot;hover&quot;, full_width = F) Happy Pleasant Unpleasant Salivating Famished Refreshed Desired Soothed Comforted Disgusted Energetic Joy Impressed Interested Irritated Melancholic Nostalgic Relaxed Revital Romantic Sad Sensual Espiritual Thirsty Well-being Guilty Alpino 27 21 11 19 24 28 15 36 11 9 10 27 19 38 5 3 3 29 4 4 7 4 2 10 17 4 Bafar 28 20 6 19 29 36 16 38 10 10 13 24 15 35 6 3 5 29 8 0 3 2 0 16 16 2 Capistrano 32 16 6 15 15 36 28 34 9 10 7 30 14 31 6 4 3 31 6 5 5 1 2 14 20 2 Chimex 26 20 7 12 16 34 15 31 13 15 11 23 19 34 7 4 5 28 13 5 3 3 2 19 24 2 Duby 33 17 9 12 20 31 18 28 10 13 8 36 24 29 9 0 2 21 9 1 5 0 2 15 24 5 2.1 The data pattern The data pattern using the chi-square is in contrast to a correlation matrix seen in PCA. The chi-square test for independence is conducted to test for the independence of the rows (sausage type) and columns (emotional response). It is the sum of squares for the observed value minus the expected value, all squared, divided by the expected value. The degrees of freedom are calculated by the number of rows minus one times the number of columns minus one of the contingency table. The number of observations dictates the effect of the chi-square distribution. Thus, a small number of observations on the order of a few hundred would lead to a smaller effect than a million obsrvations. The p-value for the chi-square is non-significant. Thus, the Null hypothesis is true that the rows are independent of the columns. In other words, there is no deviation from independence, partly due to the small number of observations. chi2 ## ## Pearson&#39;s Chi-squared test ## ## data: mt1 ## X-squared = 78.753, df = 100, p-value = 0.9425 Here we are using frequencies of qualitative data while in PCA we used quantitative data. The chi-square statistic is divided by the total sum of the data while maintaining the data structure of the table versus summing all the chi-square statistics to one number. Chi-square becomes a variance between what is expected and what is observed. Just like PCA decomposes a variance, CA decomposed chi-square. Here is the heatmap for the chi-square distribution on this data set. It is a data visualization of the chi-square values for each set of observations. It is not a correlation matrix but rather explains variance. The equivalent of the correlation coefficient in CA is the Phi prime, squared value, which is a eigenvalue in the same dimension by chance. Bafar is capturing a positive probability frequency with being Famished while Capistrano is capturing a positive probability frequency with Desired. Duby can be described closer to Joy and Impressed and away from Melancholic. Chimex is closer in Eucledian distance to Revital while Alpino is far from Revital and Bafar from Romantic. 2.2 Analysis Below is the fastPerm4CA, which computes a permutation test for CA when one has a real contingency table. Multinomial distribution is used for the resampling. fastPerm4CA can be used for large tables to test for inertia and for the test on the eigenvalues. res_fast_perm &lt;- data4PCCAR::fastPerm4CA(mt1, nIter = 100, compact = FALSE) res_fast_boot &lt;- data4PCCAR::fastBoot4CA(mt1) 2.2.1 Scree Plot Here are the results from permutation with Scree plot, with violet color indicating significant components.The estimated p-values were added to the PlotScree function. As seen here, permutation testing did not capture significant values for dimension capturing inertia. There are 4 dimension shown as there are 5 sausage types. Thus, the number of dimensions is equal to the number of row or columns minus 1. 2.2.2 Plot the asymmetric factor scores A simplex is a subspace of space with constraints. The variables are in the same space as the rows with the barycenter at the origin. A barycenter is the middle or center of gravity of the data. Information is inversely proportional to the frequency of information. Thus, the variables farthest away from other row data points explain the biggest variance. Romantic, Melancholic, Sensual, Famished, Guilty, and Espiritual capture the most variance in the data, based the simplex. The eigenvalue of .01 for the first dimension correspond to a correlation coefficient. Thus, there is very low correlation value along the first dimension as well as for the next three dimensions. # Make the simplex visible zePoly.J &lt;- ggConvexHull(Fj.a, percentage = 1, col.hull = ggplot2::alpha(&#39;darkorchid&#39;,.2), col.line = ggplot2::alpha(&#39;darkorchid&#39;,.7), line.size = .4, alpha.hull = .2, names.of.factors = &quot;Dimension &quot;) # Labels labels4CA &lt;- createxyLabels(resCA = resCA.asym) # Combine all elements you want to include in this plot map.I.sup.asym &lt;- asymMap$baseMap + zePoly.J + asymMap$I_points + asymMap$J_labels + asymMap$J_points + labels4CA + ggtitle(&#39;Asymmetric Map and Simplex&#39;) map.I.sup.asym The first dimension separates survival emotions from higher ordered emotions. For example, Energetic, Famished, and Salivating are on the right (survival emotions) while Revital, Romantic, and Desired are on the left (higher ordered emotions). The second dimension separates positive/negative responses from more neutral responses. For example, Disgusted, Romantic, and Nostalgic are separate from Desired, Salivating, and Famished. 2.2.3 Plot the symmetric plot Below is a symmetric biplot of the data. Chimex has the highest frequency probability for Romantic compared to the other sausage types while Duby is closest for the Guilty emotional response. 2.2.3.1 This is a biplot: # Create a symmetric map with sup and correct constraints map.IJ.sup.sym &lt;- symMap$baseMap + # the baseMap needs to come from your mapSup to be correct (at least for this example) symMap$I_labels + symMap$I_points + symMap$J_labels + symMap$J_points + ggtitle(&#39;Symmetric Map&#39;) + labels4CA map.IJ.sup.sym Below is the plots separated into two. If I were a grocery clerk, I would put Capistrano and Chimez together and Bafar and Alpino together as the Symmetric Row plot makes this split along the first dimension. The Symmetric Column plot splits the Survival Emotions (Guilty and Famished) from the Higher Ordered Emotions (Espiritual, Romantic, Melancholic, and Sensual) along the second dimension. 2.2.3.2 Contributions and bootstrap ratios barplots 2.2.3.2.1 Contribution barplots For CA, we plot the contributions for both rows and columns. As referenced in the analysis above, Bafar and Chimex makes a important contribution to the inertia of the chi-square distribution. Famished, Melancholic, and Sensual make an important contribution for the first dimension while. Famished, Melancholic, Romantic, and Guilty make up an important contribution for the second dimension. Energetic, Famished, and Salivating as well as Romantic and Desired are among the variable the contribution importantly to the first dimension. Disgusted and salivating are variable discussed above that also contributed importantly to the second dimension. 2.2.3.2.2 Bootstrap ratios (The next set of code is used to put two figures side to side). Bafar and Chimex as stable row variables in the analysis while Sensual and Famished are stables column variables. grid.arrange( as.grob(ba001.BR1.I),as.grob(ba002.BR1.J),as.grob(ba003.BR2.I),as.grob(ba004.BR2.J), ncol = 2,nrow = 2, top = textGrob(&quot;Bootstrap ratios&quot;, gp = gpar(fontsize = 18, font = 3)) ) Here are the contribution and bootstrap ratio plots side by side. grid.arrange( as.grob(ctrI.1),as.grob(ctrJ.1),as.grob(ctrI.2),as.grob(ctrJ.2),as.grob(ba001.BR1.I),as.grob(ba002.BR1.J),as.grob(ba003.BR2.I),as.grob(ba004.BR2.J), ncol = 4,nrow = 2, top = textGrob(&quot;Contribution &amp; Bootstrap ratios&quot;, gp = gpar(fontsize = 18, font = 3)) ) 2.3 Summary First and foremost, I prefer the symmetric plot do to better visualization. When we interpret the factor scores and loadings together, the CA revealed: *Chimex has the highest frequency probability for Romantic compared to the other sausage types *Duby is closest for the Guilty emotional response. When we interpret the factor scores and loadings separately, the CA revealed: Component 1: Capistrano and Chimez vs. Bafar and Alpino Component 2: Survival Emotions (Guilty and Famished) vs.  Higher Ordered Emotions (Espiritual, Romantic, Melancholic, and Sensual) "],["mca.html", "Chapter 3 Multiple Correspondence Analysis 3.1 Cleaning the data 3.2 Recoding the data 3.3 Analysis 3.4 Summary", " Chapter 3 Multiple Correspondence Analysis This method is an extension of PCA but analyzes categorical data instead. In some respects it is analogous to CA but uses binary data instead. MCA can also be adapted to quantitative data that is scored, for example, -5 to 5 and then binned to represent a pattern of 0 and 1 data entries. 3.1 Cleaning the data This is the same data from PCA, containing Music preferences. I cleaned the data by binned the data in to roughly equal groups. For example, for the question of Music preferences, I binned the first 4 scores into one group and left the score of 5 in its own group. There are 918 survey participants and 20 variables, including Gender. hist.Mu &lt;- hist(rawData2[,2], breaks = 20) # 1 to 4 and 5 3.2 Recoding the data head(rawData4) %&gt;% kbl() %&gt;% kable_paper(&quot;hover&quot;, full_width = F) Music Fast Dance Folk Country Classical Musical Pop Rock Metal Punk Hiphop Reg Swing RnR Alt Lat TT Opera Age Gender City Ed 2 2 1 1 2 2 1 4 3 1 1 1 1 1 2 1 1 1 1 Y F V 3 1 3 1 1 1 1 2 2 3 3 4 1 3 1 3 4 2 1 1 Y F C 3 2 3 1 2 3 4 4 2 3 3 4 1 4 3 4 5 5 1 3 Y F C 2 2 2 1 1 1 1 1 1 1 1 4 2 2 1 1 5 1 2 1 Y F C 3 2 2 3 3 2 4 3 4 1 1 2 5 3 2 1 2 4 2 2 Y F V 2 2 2 1 3 2 3 3 1 3 3 3 4 3 4 3 5 3 1 3 Y M C 2 3.3 Analysis ## ----runMCA----------------------------------------------- resMCA &lt;- epMCA(cleanData, graphs = FALSE) The Scree plot reveals that three dimensions are important based on the permutation testing and the Kaiser line. ## [1] &quot;It is estimated that your iterations will take 0.03 minutes.&quot; ## [1] &quot;R is not in interactive() mode. Resample-based tests will be conducted. Please take note of the progress bar.&quot; ## ================================================================================ The heat map is done on a Burt Table, which is a frequency table that is dummy coded for the groups of variables. It it based on disjunctive coding, a type of group coding, where either a variable is coded as a 1 or 0. Rock and Metal have a high positive correlation value as does Rock and Punk as well as Metal and Punk. Dance and Dance, Dance and Techno, and Rock and Rock and Roll have high levels of possitive correlation. In addition, Musical and Opera as well as Classical and Opera have notable positive correlation values. As referenced in the previous comments, Rock, Metal, Punk, Rock and Roll, Opera, and Classical are important contributors to the first dimension. Rock, Pop, Dance, and Tech, all of which were reference before, are important contributors to the second dimension. Rock, Metal, Punk, Musical, Classical, and Opera are important contributors to the third dimension. To read the next graph, the data point near the axis are importantly mostly to that corresponding dimension. Thus, Dance, Techno, and Pop are near the y-axis so they all contribute heavly to the second dimension. Rock, Opera, and Classical are near the x-axis so they all contribute heavly to the first dimension. The farther away from the center of gravity indicates higher variance. In addition to the variables spotted on the heat map, the next graph captures the important variables based on the contribution level by setting a cut of of 1 divided by the number of dimension (19) in out case, leaving a benchmark of 0.05263. In addition to what was stated before, dimension 1 and 2 include Latino, Swing, and Alternative. Similarly, dimension 2 and 3 capture Hiphop, Latino, and Alternative. The variables identified in the heatmap as being important and confirmed with the contribution plots was all stable, indicated by the bootstrap ratios, expect for Rock no being significant in the third dimension. It is called a Psedo Bootstrap Ratio because the variables are binned and are not exact. Here the binned data is geometrically projected in the first two dimensions. It forms somewhat of an arch with the many of the low-end binned variables, indicating low preference and low agreement, being in the third quadrant, and the high-end binned variables, indicating high preference and high agreement, being in the first and fourth quadrant. Classical, Swing, Alternative, and Rock and Roll are split by the first dimension, which makes sense as the first dimension accounts for 54% of the variance. Latino has an interesting pattern. If you have a high preference for Latino, you tend to have a mid-range preference for Alternative, Metal, Opera, and Rock and Roll. If you dont like Latino, you may not like Classical or Swing either. Latino has a similar pattern when projected in the second and third dimension, interacting with many other important contributors to these dimensions. It is mainly separated by the third dimension, which compliments earlier analysis. The Bootstrap ratio can be sub-categorized for each binned variables. For example, Latino was binned from 1 to 5 with 5 being a high preference for Latino music. The bootstrap ratio for Latino 1, Latino 2, etc. can be computed. The analysis for the binned variables being geometrically projected across the first three dimension correspond with stable binned variables in the pseduo-bootstrap ratios. If we look at the distribution color with gender, it is heterogeneous with blue (males) forming an umbrella shape and being lower than the pink (females). The Bootstrap interval allows us to form a 95% of resampling map around the mean the specific gender. We see that slightly overlap and do not form distinct group. So while the plot of the observation look heterogeneous, it is statistically homogeneous. As stated earlier, the males tend to congregate in the third quadrant more than females. Some males also tend to report lower rating on Classical, Swing, and Latino. Thus, the tolerance interval gives a better visualization, via a convex hull, for how some males report their music preferences in comparison to females. However, this should be view with caution as the confidence intervals overlap between types of gender. 3.4 Summary The Scree plot shows that there are three dimensions of interest, at least. Classical,Swing, and Rock n Roll contribute the most to dimension 1. Dance, Pop, Hiphop, and Latino contribute the most to dimension 2. Fast, Punk, Classical, and Opera contribute the most to dimension 3. In conclusion, Dance, Pop, Techo, Latino, and Hiphop form there own group in relation to the other music groups. Bootstraps for dimension 1 were significant. Based on the Important Variables MCA plot, Latino is related to Punk and Rock n Roll. Gender means overlap, indication that the distinction between groups is weak. However, the MCA Observations (by Gender) plot shows a Convex Hull. "],["bada.html", "Chapter 4 Barycentric Discriminant Analysis 4.1 Cleaning the data 4.2 Heat map 4.3 Analysis 4.4 Fixed Confusion Matrix 4.5 Random Confusion Matrix 4.6 Summary", " Chapter 4 Barycentric Discriminant Analysis This method is a robust version of discriminant analysis, which groups observations into pre-defined groups such as COVID-19 positive or negative, employed or unemployed, or married, divorced, separated, or single. BADA can even be used when n &lt;&lt; p.  4.1 Cleaning the data The data set is the same from PCA, evaluating music preferences in 931 participants. head(rawData) %&gt;% kbl() %&gt;% kable_paper(&quot;hover&quot;, full_width = F) Music Slow.songs.or.fast.songs Dance Folk Country Classical.music Musical Pop Rock Metal.or.Hardrock Punk Hiphop..Rap Reggae..Ska Swing..Jazz Rock.n.roll Alternative Latino Techno..Trance Opera Education 5 3 2 1 2 2 1 5 5 1 1 1 1 1 3 1 1 1 1 college/bachelor degree 4 4 2 1 1 1 2 3 5 4 4 1 3 1 4 4 2 1 1 college/bachelor degree 5 5 2 2 3 4 5 3 5 3 4 1 4 3 5 5 5 1 3 secondary school 5 3 2 1 1 1 1 2 2 1 4 2 2 1 2 5 1 2 1 college/bachelor degree 5 3 4 3 2 4 3 5 3 1 2 5 3 2 1 2 4 2 2 secondary school 5 3 2 3 2 3 3 2 5 5 3 4 3 4 4 5 3 1 3 secondary school 4.2 Heat map The heat map is on a matrix with the groups of education level on the rows, the variables of music preference on the columns, and the average survey score for the respective variables for each of the education levels for the table values. 4.3 Analysis #_________________________________________________ # Computations ---- # Run BADA ---- resBADA &lt;- tepBADA(XYmat, DESIGN = Ymat, graphs = FALSE) # Inferences ---- #set.seed(70301) # we had a problem # with the inference part # it is addressed iin the Fix from Luke&#39;s github nIter = 889 resBADA.inf &lt;- tepBADA.inference.battery(XYmat, DESIGN = Ymat, test.iters = nIter, graphs = FALSE) #_________________________________________________ #_________________________________________________ In the plot of the observations and the barycenter means, we see doctoral degree and currently a primary school student are distict groups from each other and the other education levels. The rest of the means are near the center of gravity. The confidence intervals confirm that currently a primary student is different from all the other education levels as is doctoral degree from all the other education levels. Here we see that Masters degree is different from doctoral degree, secondary school, and currently a primary school student. Secondary school, likewise, is different from doctoral degree, masters degree, and currently a primary school student. The tolerance intervals shows the the spread of 95% of doctoral degree observations overlap with the groups near the center of gravity as does the spread of 95% of currently a primary school student. The loading show that doctoral students tend to like Opera, Folk, Latino, Metal, and Alternative while currently a primary student individual prefer Swing, Punk, Hiphop, and Country. The contribution show that Latino, Alternative, Swing, Punk, Hiphop, and Country are important contributors to the first two dimensions while the bootstrap ratios show that Latino, Alternative, Swing, Hiphop, and Country and stable variables. 4.4 Fixed Confusion Matrix According to chance, their is a 0.1667 or 16.67% likelihood to discriminant to the barycenter groups. The fixed confusion matrix predicted at a accuracy of 0.20, which is more than by change. Thus, the level of education is a modest benchmark to classify music preference. The horizontal titles are the actual numbers while the vertical titles are the predicted numbers. The diagonal from the upper left to the bottom right represents the hits while the other values represent the misses. fixed_cm &lt;-resBADA.inf$Inference.Data$loo.data$fixed.confuse head(fixed_cm) %&gt;% kbl() %&gt;% kable_paper(&quot;hover&quot;, full_width = F) .college/bachelor degree .secondary school .primary school .masters degree .doctorate degree .currently a primary school pupil .college/bachelor degree 49 91 9 16 3 2 .secondary school 54 211 21 20 0 0 .primary school 24 103 22 6 0 0 .masters degree 53 127 9 30 1 2 .doctorate degree 1 4 0 1 0 0 .currently a primary school pupil 19 33 12 4 1 3 resBADA.inf$Inference.Data$loo.data$fixed.acc ## [1] 0.3383459 4.5 Random Confusion Matrix The Random Confusion Matrix only predicted by 0.1664, which under-performed compared to the liklihood by chance alone. The Random Confusion Matrix is a method to mimic training and testing dat sets. It utilizes Jackknife whereby one observation is left out, and a permutation test is run. The BADA is performed on the Leave One Out Data Set and the left out data point is used to minimize the distance to barycenter. Thus, random confusion matrices are a way of validating the fixed confusion matrix through Jackknife and permutation testing. .college/bachelor degree.actual .secondary school.actual .primary school.actual .masters degree.actual .doctorate degree.actual .currently a primary school pupil.actual .college/bachelor degree.predicted 34 92 10 18 3 3 .secondary school.predicted 60 208 21 21 0 2 .primary school.predicted 28 103 21 6 0 0 .masters degree.predicted 59 127 9 27 2 2 .doctorate degree.predicted 2 4 0 1 0 0 .currently a primary school pupil.predicted 17 35 12 4 0 0 ## [1] 0.311493 4.6 Summary The Scree Plot shows that the first three dimension are important. The main take away from the confidence intervals plot is that currently a primary school student and doctoral student are different from each other and all other groups. However, the random confusion matrix showed a poor accuracy in the prediction strength of the BADA algorithm. "],["dica.html", "Chapter 5 Discriminant Correspondence Analysis 5.1 Analysis 5.2 Fixed Confusion Matrix 5.3 Random Confusion Matrix 5.4 Summary", " Chapter 5 Discriminant Correspondence Analysis This method is an extension of Discriminant Analysis and Correspondence Analysis, with the caveat of containing nominal variables for the pre-defined groups. Traditionally, a comparison between a training data set and testing data set is done to evaluate the effectiveness of the classification ability of the analysis. This is a for loop that is used for the color designation later in this method. ## foo function ---- # to be used later foo &lt;- function(x) { xuniq &lt;- unique(x) N &lt;- length(xuniq) res &lt;- rep(NA, N) for (i in 1:N) { res[i] &lt;- sum(x == xuniq[i]) } return(res) } I binned the variables just like in MCA, but I did not bin the discriminant varibale of alcohol consumption. head(XYmat) %&gt;% kbl() %&gt;% kable_paper(&quot;hover&quot;, full_width = F) Music Fast Dance Folk Country Classical Musical Pop Rock Metal Punk Hiphop Reg Swing RnR Alt Lat TT Opera 2 2 1 1 2 2 1 4 3 1 1 1 1 1 2 1 1 1 1 1 3 1 1 1 1 2 2 3 3 4 1 3 1 3 4 2 1 1 2 3 1 2 3 4 4 2 3 3 4 1 4 3 4 5 5 1 3 2 2 1 1 1 1 1 1 1 1 4 2 2 1 1 5 1 2 1 2 2 3 3 2 4 3 4 1 1 2 5 3 2 1 2 4 2 2 2 2 1 3 2 3 3 1 3 3 3 4 3 4 3 5 3 1 3 5.0.1 Heatmap 5.1 Analysis #_________________________________________________ # Computations ---- ## Run DiCA ---- resDiCA &lt;- tepDICA(XYmat, make_data_nominal = TRUE, DESIGN = Ymat, graphs = FALSE) ## Inferences ---- set.seed(70301) # set the seed # for random so that we all have the same results. nIter &lt;- 100 resDiCA.inf &lt;- tepDICA.inference.battery(XYmat, DESIGN = Ymat, test.iters = nIter, graphs = FALSE) The Scree plot reveals that the there are two dimensions with the first capturing almost 70% of the total variance and the second capturing the remaining amount. The group means for the amount of alcohol consumed are distinct: Never drinks is separate from the social drinkers, which both are separate from the drinks a lot category. The confidence intervals confirm that the group means are distinct from each other. The tolerance inteval, however, show that the spread of 95% of the observations overlap between the three categorical variables for alcohol consumption. If you drink a lot you tend to like Metal and Swing more than others. If you are a social drinker you tend to like Latino and Pop whereas if you have never consumed alcohol, you prefer Country and Swing. As referenced in the above analysis, high ratings of Metal, Swing, and Pop are important contributors to first dimension. Country is a important contributor to the second dimension. Latino and Pop are both significant bootstrap ratios. 5.2 Fixed Confusion Matrix The Fixed Confusion matrix performs slightly better than change (0.39 vs. 0.33). .drink a lot .social drinker .never .drink a lot 101 213 34 .social drinker 56 214 33 .never 47 182 46 ## [1] 0.3898488 5.3 Random Confusion Matrix The random confusion matrix also performs slightly better than chance (0.37 vs. 0.33). .drink a lot.actual .social drinker.actual .never.actual .drink a lot.predicted 98 216 36 .social drinker.predicted 58 202 39 .never.predicted 48 191 38 ## [1] 0.3650108 5.4 Summary Discriminant Correspondence Analysis have feature of BADA and MCA with a emphasis on predicting the closest distance to a group mean binned data. The analysis revealed that heavy drinkers prefer Metal and Swing while social drinkers tend to like Latino and Pop. Those that have never consumed alcohol prefer Country and Swing. The fixed and random matrices preformed slightly better than chance. "],["plsc.html", "Chapter 6 Partial Least Square Correlation", " Chapter 6 Partial Least Square Correlation Using information from the same observations, PLSC finds the correlation of multivariate data in two data tables. The first step is to obtain latent variables from linear combination similar to PCA. Analogously, these latent variables maximize the covariance between the tables. Additionally, factor scores in PCA are akin to latent variables in PLSC while loadings in PCA are akin to saliences in PLSC. Bootstrap and permutation tests are added to the analysis when inferential PSLC is indicated. A clean start is achieved by removing data and values from the working environment, closing all open graphic devices, and reporting the memory usage. The latter function, garbage collection, may help R return memory to the operating system after removing a large object. The following code refines the ggplot2 function by removing error messages for multiple overlaps. ## [1] 883 33 head(hobbies_3) %&gt;% kbl() %&gt;% kable_paper(&quot;hover&quot;, full_width = F) Hist Psych Politics Math Physics Internet PC Econ Bio Chem Read Geo Lang Med Law Cars Art Religion Outdoor Dance Music Writing Passive Sp Actice Sp Garden Celeb Shop STEM Theatre Friends Adrenaline Sp Pets Gender 1 5 1 3 3 5 3 5 3 3 3 3 5 3 1 1 1 1 5 3 3 2 1 5 5 1 4 4 2 5 4 4 female 1 3 4 5 2 4 4 5 1 1 4 4 5 1 2 2 2 1 1 1 1 1 1 1 1 2 3 3 2 4 2 5 female 1 2 1 5 2 4 2 4 1 1 5 2 5 2 3 1 5 5 5 5 5 5 5 2 1 1 4 2 5 5 5 5 female 4 4 5 4 1 3 1 2 3 3 5 4 4 2 5 1 5 4 1 1 1 3 1 1 1 2 4 3 1 2 1 1 female 3 2 3 2 2 2 2 2 3 3 5 2 3 3 2 3 1 4 4 1 3 1 3 1 4 3 3 3 2 4 2 1 female 5 3 4 2 3 4 4 1 4 4 3 3 4 4 3 5 2 2 5 1 5 1 5 4 2 1 2 3 1 3 3 2 male As a background to the data, I have a hobbies data set that is organized into two natural sub-sets. The first thirteen were college major themes (history, psychology, math) and the rest were post-college themes (law, medcine) as well as lifelong hobbies (friends, sports, pets). Thus, I based my two matrices along a linear lifespan or life journey. 6.0.1 Correlation plot Politics and Law are highly correlated as is Physics and Science and Technology. PC and cars as well as PC and Science and Technology have substantial correlations as well. Biology and Chemistry with Medicine have very high correlations while Reading and Theater have a fair amount. An interest in Reading is negatively correlated with an interest in Cars. 6.0.2 Analysis #Next I run the PLSC function PLSC = tepPLS(Xmat, Ymat, DESIGN = gender, graphs = FALSE) 6.0.3 Inferences 6.0.4 Graphics 6.0.5 Color Scheme for Gender 6.0.6 Latent variable 1 6.0.7 Confidence Intervals 6.0.8 Contributions for LV1 6.0.9 Bootstrap 6.0.10 Latent variable 2 6.0.11 Confidence Intervals 6.0.12 Contributions for LV2 6.0.13 Bootstrap 6.0.14 Conclusion Biology and Chemistry are highly correlated with Medicine while Reading is negatively correlated with Cars.Males and Females form distinct groups along the X and Y LV in both dimensions.Biology, Chemistry, Medicine correspond to the female group on LV1.Physics, Math, and Politics correspond to the male group on LV2 as does Adrenaline Sport, Cars, and Law. Shopping is a quality of females on LV2. "],["distatis.html", "Chapter 7 DISTATIS 7.1 Analysis 7.2 Graphs", " Chapter 7 DISTATIS This method combines Multi-Dimensional Scaling and STATIS. The STATIS step follows the MDS step and is an optimization step. Thus, optimum weights are added to the data table. Further, the sqaure of Eucledian distances are used to group variable for each matrix. DiSTATIS is specifically a I x I x K matrix where I are objects and K are people. head(DistanceCube) %&gt;% kbl() %&gt;% kable_paper(&quot;hover&quot;, full_width = F) FCAR.J1 SRUD.J1 FBAU.J1 FROC.J1 SFED.J1 SREY.J1 SKLE.J1 FCLL.J1 FCLP.J1 SRAD.J1 SRAA.J1 FROU.J1 FHUE.J1 SBEA.J1 FCAR.J2 SRUD.J2 FBAU.J2 FROC.J2 SFED.J2 SREY.J2 SKLE.J2 FCLL.J2 FCLP.J2 SRAD.J2 SRAA.J2 FROU.J2 FHUE.J2 SBEA.J2 FCAR.J3 SRUD.J3 FBAU.J3 FROC.J3 SFED.J3 SREY.J3 SKLE.J3 FCLL.J3 FCLP.J3 SRAD.J3 SRAA.J3 FROU.J3 FHUE.J3 SBEA.J3 FCAR.J4 SRUD.J4 FBAU.J4 FROC.J4 SFED.J4 SREY.J4 SKLE.J4 FCLL.J4 FCLP.J4 SRAD.J4 SRAA.J4 FROU.J4 FHUE.J4 SBEA.J4 FCAR.J5 SRUD.J5 FBAU.J5 FROC.J5 SFED.J5 SREY.J5 SKLE.J5 FCLL.J5 FCLP.J5 SRAD.J5 SRAA.J5 FROU.J5 FHUE.J5 SBEA.J5 FCAR.J6 SRUD.J6 FBAU.J6 FROC.J6 SFED.J6 SREY.J6 SKLE.J6 FCLL.J6 FCLP.J6 SRAD.J6 SRAA.J6 FROU.J6 FHUE.J6 SBEA.J6 FCAR.J7 SRUD.J7 FBAU.J7 FROC.J7 SFED.J7 SREY.J7 SKLE.J7 FCLL.J7 FCLP.J7 SRAD.J7 SRAA.J7 FROU.J7 FHUE.J7 SBEA.J7 FCAR.J8 SRUD.J8 FBAU.J8 FROC.J8 SFED.J8 SREY.J8 SKLE.J8 FCLL.J8 FCLP.J8 SRAD.J8 SRAA.J8 FROU.J8 FHUE.J8 SBEA.J8 FCAR.J9 SRUD.J9 FBAU.J9 FROC.J9 SFED.J9 SREY.J9 SKLE.J9 FCLL.J9 FCLP.J9 SRAD.J9 SRAA.J9 FROU.J9 FHUE.J9 SBEA.J9 FCAR.J10 SRUD.J10 FBAU.J10 FROC.J10 SFED.J10 SREY.J10 SKLE.J10 FCLL.J10 FCLP.J10 SRAD.J10 SRAA.J10 FROU.J10 FHUE.J10 SBEA.J10 FCAR.J11 SRUD.J11 FBAU.J11 FROC.J11 SFED.J11 SREY.J11 SKLE.J11 FCLL.J11 FCLP.J11 SRAD.J11 SRAA.J11 FROU.J11 FHUE.J11 SBEA.J11 FCAR.J12 SRUD.J12 FBAU.J12 FROC.J12 SFED.J12 SREY.J12 SKLE.J12 FCLL.J12 FCLP.J12 SRAD.J12 SRAA.J12 FROU.J12 FHUE.J12 SBEA.J12 FCAR.J13 SRUD.J13 FBAU.J13 FROC.J13 SFED.J13 SREY.J13 SKLE.J13 FCLL.J13 FCLP.J13 SRAD.J13 SRAA.J13 FROU.J13 FHUE.J13 SBEA.J13 FCAR.J14 SRUD.J14 FBAU.J14 FROC.J14 SFED.J14 SREY.J14 SKLE.J14 FCLL.J14 FCLP.J14 SRAD.J14 SRAA.J14 FROU.J14 FHUE.J14 SBEA.J14 FCAR.J15 SRUD.J15 FBAU.J15 FROC.J15 SFED.J15 SREY.J15 SKLE.J15 FCLL.J15 FCLP.J15 SRAD.J15 SRAA.J15 FROU.J15 FHUE.J15 SBEA.J15 FCAR.J16 SRUD.J16 FBAU.J16 FROC.J16 SFED.J16 SREY.J16 SKLE.J16 FCLL.J16 FCLP.J16 SRAD.J16 SRAA.J16 FROU.J16 FHUE.J16 SBEA.J16 FCAR.J17 SRUD.J17 FBAU.J17 FROC.J17 SFED.J17 SREY.J17 SKLE.J17 FCLL.J17 FCLP.J17 SRAD.J17 SRAA.J17 FROU.J17 FHUE.J17 SBEA.J17 FCAR.J18 SRUD.J18 FBAU.J18 FROC.J18 SFED.J18 SREY.J18 SKLE.J18 FCLL.J18 FCLP.J18 SRAD.J18 SRAA.J18 FROU.J18 FHUE.J18 SBEA.J18 FCAR.J19 SRUD.J19 FBAU.J19 FROC.J19 SFED.J19 SREY.J19 SKLE.J19 FCLL.J19 FCLP.J19 SRAD.J19 SRAA.J19 FROU.J19 FHUE.J19 SBEA.J19 FCAR.J20 SRUD.J20 FBAU.J20 FROC.J20 SFED.J20 SREY.J20 SKLE.J20 FCLL.J20 FCLP.J20 SRAD.J20 SRAA.J20 FROU.J20 FHUE.J20 SBEA.J20 FCAR.J21 SRUD.J21 FBAU.J21 FROC.J21 SFED.J21 SREY.J21 SKLE.J21 FCLL.J21 FCLP.J21 SRAD.J21 SRAA.J21 FROU.J21 FHUE.J21 SBEA.J21 FCAR.J22 SRUD.J22 FBAU.J22 FROC.J22 SFED.J22 SREY.J22 SKLE.J22 FCLL.J22 FCLP.J22 SRAD.J22 SRAA.J22 FROU.J22 FHUE.J22 SBEA.J22 FCAR.J23 SRUD.J23 FBAU.J23 FROC.J23 SFED.J23 SREY.J23 SKLE.J23 FCLL.J23 FCLP.J23 SRAD.J23 SRAA.J23 FROU.J23 FHUE.J23 SBEA.J23 FCAR.J24 SRUD.J24 FBAU.J24 FROC.J24 SFED.J24 SREY.J24 SKLE.J24 FCLL.J24 FCLP.J24 SRAD.J24 SRAA.J24 FROU.J24 FHUE.J24 SBEA.J24 FCAR.J25 SRUD.J25 FBAU.J25 FROC.J25 SFED.J25 SREY.J25 SKLE.J25 FCLL.J25 FCLP.J25 SRAD.J25 SRAA.J25 FROU.J25 FHUE.J25 SBEA.J25 FCAR.J26 SRUD.J26 FBAU.J26 FROC.J26 SFED.J26 SREY.J26 SKLE.J26 FCLL.J26 FCLP.J26 SRAD.J26 SRAA.J26 FROU.J26 FHUE.J26 SBEA.J26 FCAR.J27 SRUD.J27 FBAU.J27 FROC.J27 SFED.J27 SREY.J27 SKLE.J27 FCLL.J27 FCLP.J27 SRAD.J27 SRAA.J27 FROU.J27 FHUE.J27 SBEA.J27 FCAR.J28 SRUD.J28 FBAU.J28 FROC.J28 SFED.J28 SREY.J28 SKLE.J28 FCLL.J28 FCLP.J28 SRAD.J28 SRAA.J28 FROU.J28 FHUE.J28 SBEA.J28 FCAR.J29 SRUD.J29 FBAU.J29 FROC.J29 SFED.J29 SREY.J29 SKLE.J29 FCLL.J29 FCLP.J29 SRAD.J29 SRAA.J29 FROU.J29 FHUE.J29 SBEA.J29 FCAR.J30 SRUD.J30 FBAU.J30 FROC.J30 SFED.J30 SREY.J30 SKLE.J30 FCLL.J30 FCLP.J30 SRAD.J30 SRAA.J30 FROU.J30 FHUE.J30 SBEA.J30 FCAR.J31 SRUD.J31 FBAU.J31 FROC.J31 SFED.J31 SREY.J31 SKLE.J31 FCLL.J31 FCLP.J31 SRAD.J31 SRAA.J31 FROU.J31 FHUE.J31 SBEA.J31 FCAR.J32 SRUD.J32 FBAU.J32 FROC.J32 SFED.J32 SREY.J32 SKLE.J32 FCLL.J32 FCLP.J32 SRAD.J32 SRAA.J32 FROU.J32 FHUE.J32 SBEA.J32 FCAR.J33 SRUD.J33 FBAU.J33 FROC.J33 SFED.J33 SREY.J33 SKLE.J33 FCLL.J33 FCLP.J33 SRAD.J33 SRAA.J33 FROU.J33 FHUE.J33 SBEA.J33 FCAR.J34 SRUD.J34 FBAU.J34 FROC.J34 SFED.J34 SREY.J34 SKLE.J34 FCLL.J34 FCLP.J34 SRAD.J34 SRAA.J34 FROU.J34 FHUE.J34 SBEA.J34 FCAR.J35 SRUD.J35 FBAU.J35 FROC.J35 SFED.J35 SREY.J35 SKLE.J35 FCLL.J35 FCLP.J35 SRAD.J35 SRAA.J35 FROU.J35 FHUE.J35 SBEA.J35 FCAR.J36 SRUD.J36 FBAU.J36 FROC.J36 SFED.J36 SREY.J36 SKLE.J36 FCLL.J36 FCLP.J36 SRAD.J36 SRAA.J36 FROU.J36 FHUE.J36 SBEA.J36 FCAR.J37 SRUD.J37 FBAU.J37 FROC.J37 SFED.J37 SREY.J37 SKLE.J37 FCLL.J37 FCLP.J37 SRAD.J37 SRAA.J37 FROU.J37 FHUE.J37 SBEA.J37 FCAR.J38 SRUD.J38 FBAU.J38 FROC.J38 SFED.J38 SREY.J38 SKLE.J38 FCLL.J38 FCLP.J38 SRAD.J38 SRAA.J38 FROU.J38 FHUE.J38 SBEA.J38 FCAR.J39 SRUD.J39 FBAU.J39 FROC.J39 SFED.J39 SREY.J39 SKLE.J39 FCLL.J39 FCLP.J39 SRAD.J39 SRAA.J39 FROU.J39 FHUE.J39 SBEA.J39 FCAR.J40 SRUD.J40 FBAU.J40 FROC.J40 SFED.J40 SREY.J40 SKLE.J40 FCLL.J40 FCLP.J40 SRAD.J40 SRAA.J40 FROU.J40 FHUE.J40 SBEA.J40 FCAR.J41 SRUD.J41 FBAU.J41 FROC.J41 SFED.J41 SREY.J41 SKLE.J41 FCLL.J41 FCLP.J41 SRAD.J41 SRAA.J41 FROU.J41 FHUE.J41 SBEA.J41 FCAR.J42 SRUD.J42 FBAU.J42 FROC.J42 SFED.J42 SREY.J42 SKLE.J42 FCLL.J42 FCLP.J42 SRAD.J42 SRAA.J42 FROU.J42 FHUE.J42 SBEA.J42 FCAR.J43 SRUD.J43 FBAU.J43 FROC.J43 SFED.J43 SREY.J43 SKLE.J43 FCLL.J43 FCLP.J43 SRAD.J43 SRAA.J43 FROU.J43 FHUE.J43 SBEA.J43 FCAR.J44 SRUD.J44 FBAU.J44 FROC.J44 SFED.J44 SREY.J44 SKLE.J44 FCLL.J44 FCLP.J44 SRAD.J44 SRAA.J44 FROU.J44 FHUE.J44 SBEA.J44 FCAR.J45 SRUD.J45 FBAU.J45 FROC.J45 SFED.J45 SREY.J45 SKLE.J45 FCLL.J45 FCLP.J45 SRAD.J45 SRAA.J45 FROU.J45 FHUE.J45 SBEA.J45 FCAR.J46 SRUD.J46 FBAU.J46 FROC.J46 SFED.J46 SREY.J46 SKLE.J46 FCLL.J46 FCLP.J46 SRAD.J46 SRAA.J46 FROU.J46 FHUE.J46 SBEA.J46 FCAR 0 0 1 0 0 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 SRUD 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 0 1 0 1 1 0 1 0 0 1 0 0 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 FBAU 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1 0 1 0 0 1 0 0 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 1 0 0 0 1 1 0 0 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 0 0 1 FROC 0 0 1 0 0 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 1 0 0 0 1 1 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 0 1 0 1 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 SFED 0 0 1 0 0 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 SREY 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 7.1 Analysis # **** Computations ---- ## runDistatis-------------------------------- resDistatis &lt;- distatis(DistanceCube, nfact2keep = 10) n.active &lt;- dim(DistanceCube)[3] 7.2 Graphs The Rv coefficient is a correlation coefficient for covariance matrices. The Rv Graph shows that French Judges with Information are likely to judge similarly to other French Judges with Information as are South African judges and other South African judges. Judges, surprisingly, do not separate along the second dimension with respect to nationality. ## ----RVwithCI----------------------------------- # First the means # A tweak for colors in.tmp &lt;- sort(rownames(color4Judges.list$gc), index.return = TRUE)$ix col4Group &lt;- color4Judges.list$gc[in.tmp] # gg.rv.means &lt;- PTCA4CATA::createFactorMap( JudgesMeans, axis1 = 1, axis2 = 2, constraints = gg.rv.graph.out$constraints, col.points = col4Group , alpha.points = 1, # no transparency col.labels = col4Group) # dimnames(BootCube$BootCube)[[2]] &lt;- paste0(&#39;dim &#39;,1: dim(BootCube$BootCube)[[2]]) #c(&#39;Dim1&#39;,&#39;Dim2&#39;) GraphElli.rv &lt;- MakeCIEllipses( BootCube$BootCube[,1:2,], names.of.factors = c(&quot;dim 1&quot;,&quot;dim 2&quot;), col = col4Group, p.level = .95) a2d.gg.RVMap.CI &lt;- a2b.gg.RVmap + gg.rv.means$zeMap_dots + GraphElli.rv # dev.new() print(a2d.gg.RVMap.CI) ## ----meansRV------------------------------------ #knitr::kable(JudgesMeans[,1:3]) ## ----mapa2d ----------------- #print(a2d.gg.RVMap.CI ) The confidence intervals overlap so groups are not distinct. ## HCA ## Hierarchical Clustering Analysis (HCA) D &lt;- dist(resDistatis$res4Cmat$G, method = &quot;euclidean&quot;) fit &lt;- hclust(D, method = &quot;ward.D2&quot;) a05.tree4participants &lt;- fviz_dend(fit, k = 1, k_colors = &#39;burlywood4&#39;, label_cols = color4Judges.list$oc[fit$order], cex = .7, xlab = &#39;Participants&#39;, main = &#39;Cluster Analysis: Participants&#39;) ## ---- plothca -------------------- print(a05.tree4participants) No apparent pattern emerges from the Hierarchnical Clustering Analysis. FBAU and FCLL form a cluster of similarity as do SBEA, FCAR, and FROC as well as FCLP and FROU. FROC, FCAR, SBEA, and SKLE form a distinct cluster along dimension 1 while SRAA, FBAU, and SFED form a distinct cluster slong dimension 2. ## HCA products ------ nFac4Prod = 5 D4Prod &lt;- dist( resDistatis$res4Splus$F[,1:nFac4Prod], method = &quot;euclidean&quot;) fit4Prod &lt;- hclust(D4Prod, method = &quot;ward.D2&quot;) b3.tree4Product &lt;- fviz_dend(fit4Prod, k = 1, k_colors = &#39;burlywood4&#39;, label_cols = color4Products[fit4Prod$order], cex = .7, xlab = &#39;Products&#39;, main = &#39;Cluster Analysis: Products&#39;) ## ----plot hca Prod --------------------- print(b3.tree4Product) There seems like four major clusters with the first (SRAA, FBAU, and SFED) and fourth (FROC, FCAR, SBEA, and SKLE) corresponding well with the projections along dimensions 1 and 2 seen earlier. 7.2.1 Summary Two central cluster were seen in the analysis with the first (SRAA, FBAU, and SFED) being seen along the first dimension and the fourth (FROC, FCAR, SBEA, and SKLE) be seen along the second dimension. "],["mfa.html", "Chapter 8 MFA 8.1 Analysis 8.2 Summary", " Chapter 8 MFA This method is an extension of PCA with a multi-data table scenario. First, MFA does a PCA on each Table and normalizes each one. Second, the normalize tables are aggregated in a multi-dimensional table and another non-normalized PCA is run to generate factor scores and loadings. MFA specifically is a I by J by K matrix where I and J are objects and K are people. head(ratings5) %&gt;% kbl() %&gt;% kable_paper(&quot;hover&quot;, full_width = F) Fr.Info.J1 Fr.Info.J2 Fr.Info.J3 Fr.Info.J4 Fr.Info.J5 Fr.Info.J6 Fr.Info.J7 Fr.Info.J8 Fr.Info.J9 Fr.Info.J10 Fr.Info.J11 Fr.Info.J12 Fr.No.Info.J13 Fr.No.Info.J14 Fr.No.Info.J15 Fr.No.Info.J16 Fr.No.Info.J17 Fr.No.Info.J18 Fr.No.Info.J19 Fr.No.Info.J20 Fr.No.Info.J21 Fr.No.Info.J22 Fr.No.Info.J23 Fr.No.Info.J24 Fr.No.Info.J25 SA.Info.J26 SA.Info.J27 SA.Info.J28 SA.Info.J29 SA.Info.J30 SA.Info.J31 SA.Info.J32 SA.Info.J33 SA.Info.J34 SA.Info.J35 SA.Info.J36 SA.Info.J37 SA.Info.J38 SA.No.Info.J39 SA.No.Info.J40 SA.No.Info.J41 SA.No.Info.J42 SA.No.Info.J43 SA.No.Info.J44 SA.No.Info.J45 SA.No.Info.J46 FCAR 2 3 3 2 2 2 1 2 1 3 1 1 2 1 1 3 3 2 2 1 3 1 3 2 4 4 5 1 1 6 3 1 8 1 3 3 2 2 1 3 3 6 4 1 3 3 SRUD 2 4 3 1 2 2 1 3 1 2 1 1 4 2 1 4 2 3 2 2 3 1 2 3 5 4 1 1 2 4 4 2 5 2 2 4 5 5 3 1 5 4 3 4 3 1 FBAU 4 2 3 2 3 3 1 3 1 3 3 4 4 3 2 5 2 1 1 2 3 2 4 3 5 2 2 3 4 1 3 3 4 1 4 6 4 4 2 4 3 5 5 4 4 4 FROC 2 3 3 3 2 2 1 2 2 3 3 3 1 3 2 6 3 3 1 1 2 1 3 2 1 3 1 1 3 7 1 1 7 2 3 5 2 2 2 4 1 6 6 1 1 3 SFED 2 3 2 3 1 2 4 3 2 2 3 3 4 1 2 6 1 1 1 2 1 1 1 4 1 1 5 5 1 3 2 3 6 2 3 8 3 4 2 5 4 5 1 2 1 5 SREY 3 1 5 3 1 4 2 3 3 1 1 5 1 1 1 5 4 1 4 1 2 2 4 3 3 4 5 1 2 1 4 2 2 2 2 7 4 1 1 3 1 1 3 3 3 2 8.1 Analysis ## call MFA ---- resMFA &lt;- FactoMineR::MFA(ratings5, group = nVar4Nations5, type = rep(&quot;s&quot;, nNations5), name.group = my_list$NamesOfNations, graph = FALSE # TRUE first pass only ) # distatis ---- resDistatis &lt;- distatis(cubeOfDistances) # **** Graphs ---- color4NationsB &lt;- my_list$Color4NationsB color4WinesB&lt;- my_list$Color4WinesB # ... MFA ---- val.p &lt;- resMFA$eig[,1] val.tau &lt;- resMFA$eig[,2] ctr.Judges.mfa &lt;- resMFA$group$coord 8.1.1 Graphs Interestingly, Nationality and Amount of Information are not grouped together. SKLE, FCLL, FCLP, and FROU are separated from SRAD, and SREY along the first dimension. SRAA, SFED, and FBAU are separated from FCAR, and FHUE along the second dimension. Here, there is evidence that French and South African Judges that contribute more importantly to the analysis are separated by the first dimension. 8.2 Summary SKLE, FCLL, FCLP, and FROU correspond South African Judges and SRAD, and SREY correspond to French Judges. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
